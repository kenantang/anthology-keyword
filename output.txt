goldfish, 2
context truncation, 24
conversationalist, 2
shared interests, 165
TV shows, 67
all-vs-all, 947
natural dialog, 1720
co-rating, 7
BlenderBot BPE, 0
overexpressed, 0
conversational attributes, 51
long-context, 1040
granularity, 268
joint goal accuracy, 60
PrLM, 5
special token, 69
two-way classification, 112
binary classification, 306
auxilary relationship, 55
auxilary edge, 7
auxilary node, 0
gate control GNN, 0
gate fusion GNN, 0
DST perspective, 3
noise-free, 21
indicator token, 9
copy mechanism, 1480
10 different random seeds, 20
5 different random seeds, 0
confuse the model, 41
core components, 117
taxi, 13
bias mitigation, 43
adequacy, 172
focal loss, 12
statistical artifacts, 7
multitask-setting, 262
multi-task setting, 740
reversed, 125
partial input bias, 6
decent prediction, 11
preserve the meaning, 153
dual-pivot, 1
fine-tuning pair, 200
shared structure, 326
out-of-the-box, 115
post-training, 488
pivot pair, 95
completely unsupervised, 103
partially unsupervised, 60
fourfold, 4
light, 653
lensing module, 0
synthetic bitext, 6
bootstrapped bitext, 8
unnormalized score, 0
degenerate, 50
degraded, 330
summand, 0
summands, 0
Arabic-English, 805
German-English, 1310
hubness, 10
hub, 74
trainable components, 46
to some extent, 2560
resource-rich, 690
resource-poor, 169
high-resource, 1770
low-resource, 2060
lexical constrained decoding, 22
left-to-right, 414
translation prefix, 72
text-infilling, 30
text infilling MLM, 0
text infilling masked, 7
hard constraints, 76
maximum a posteriori, 10
decoding time, 351
multiple iterations, 18
post-edited, 495
given prefix, 238
given suffix, 157
burden, 87
terminology constraints, 41
nested NER, 44
non-crossing, 76
nested, 184
tree fragments, 28
chart-based, 1920
span representation, 191
subspan, 2
sub-span, 40
cursor, 6
n-ary, 63
bos, 127
fencepost, 0
fencepost representation, 0
deep biaffine function, 0
boundary, 574
shared boundary, 21
CYK algorithm, 4
CKY algorithm, 14
multiple children, 23
near-optimal, 40
linearize, 122
semi-Markov, 41
shortcut, 45
reorder, 410
preserve order, 21
hypergraph, 41
headword, 58
fruitful, 87
flatter minima, 2
flat, 241
smoothed loss landscapes, 1
incorrect boundary, 5
sharpness, 4
miscalibration, 3
sharpness miscalibration, 0
biaffine decoder, 10
smoothing visualization, 1
flat NER, 21
auxilary embedding, 56
over-confidence, 83
over-confident, 60
miscalibrated, 1
reliability diagram, 1
ECE, 161
expected calibration error, 2
loss landscape, 7
geometric property, 5
chaotic, 69
recall-sensitive, 40
translationese, 76
inverse model, 66
denoising auto-encoding, 30
DAE, 46
third-party, 51
Google Translator, 21
natural inputs, 2300
self-training, 536
joint BPE, 10
executable, 62
Excel, 33
expansion pruning, 6
verbatim, 20
repartitioning, 0
fictional domains, 5
connected component, 20
accessor, 6
increased latency, 6
last token, 1670
last token embedding, 224
three times, 494
i.i.d., 16
bold red font, 9
aggressive pruning, 4
conservative pruning, 0
system-generated, 766
relative quality, 189
one-point deterministic, 5
probability correlation, 15
probability correlated, 36
one-point, 594
reward shaping, 7
quality estimation, 383
two-stage, 568
demonstrations, 1840
exploit metrics, 152
novel n-grams, 58
novel ngrams, 43
computational overhead, 78
click here, 120
hyperlink, 43
path-based, 357
last but not least, 80
high-quality negative, 40
entity-to-concept, 155
coarse-to-fine, 146
silver standard, 60
case marker, 60
case polysemy, 45
case homosemy, 0
glossing, 102
deep cases, 247
loosely based, 19
verse, 108
Norwegian Bokmål, 18
artefact, 30
artifact, 104
Fisher, 189
adpositions, 9
clitics, 43
syncretism, 10
well-generalized, 65
2-model ensemble, 287
3-model ensemble, 153
ensemble-distillation, 34
weight-sharing, 19
alternating updates, 5
gating factor, 1
paired student t-test, 0
ensemble variance, 6
branches, 169
training-from-scratch, 109
low-resource datasets, 470
rich-resource datasets, 144
high-resource datasets, 282
low variance, 60
norm constraint, 7
well-trained, 1040
API, 240
APIs, 275
deployment strategy, 6
feature attribution, 4080
hand-crafted, 337
semi-automatic, 434
glass-box, 12
binary calibration, 2
null response, 0
LIME and SHAP, 0
SHAP and LIME, 0
random forest, 191
glass box, 48
fool, 41
union, 145
utterly fail, 0
utterly fails, 0
utterly failed, 0
in-domain OOD, 25
strictly black-box, 2
knowledge embedding, 894
closed simile, 1
open simile, 4
three distractors, 1870
two distractors, 15
usage frequencies, 37
context diversity, 267
context diversities, 127
equally divided, 2
copula, 15
PCA, 42
t-SNE, 23
knowledge-enhanced, 690
equivalent prompts, 2
backdoor, 24
backdoor paths, 0
backdoor criterion, 0
structural causal model, 41
causal paths, 6
verbalization, 32
further pretrain, 115
sample disparity, 3
intuitive solution, 12
rank consistency, 66
revise, 100
revision, 245
naturally occuring, 102
erroneous translations, 87
continued training, 201
continued pre-training, 22
continued pretraining, 40
semantic divergence, 92
local errors, 104
bicleaner, 4
medium-frequency words, 4
rejuvenation, 4
potentially idiomatic expressions, 14
bottom three layers, 5
top three layers, 18
metonym, 2
canonical correlation analysis, 51
CCA, 37
amnesic, 2
iterative null-space projection, 4
INLP, 68
within-domain, 993
falsify, 6
clausal, 62
resource-intensive, 120
workaround, 7
parameter-intensive, 16
unlabelled finetuned, 10
boundary detection, 87
dialogic discourse, 7
background claim, 19
own claim, 20
independent signals, 17
unit tests, 3090
strategic, 1720
non-compositional questions, 9
compositional questions, 115
compositional, 532
non-compositional, 83
self-consistency, 37
self-consistency dialog, 20
invariance, 178
cropping, 9
populate, 61
human baseline, 1340
$, 0
trip the model, 54
2-choice, 271
3-choice, 230
disjunction, 51
atomicity, 2
human ceiling, 5
BioNLP, 669
Anglo-centric, 2
single-human, 577
community-driven, 83
north star, 19
search engine logs, 76
real-world distribution, 80
maintenance, 175
-STS, 90400
query-query, 1260
dishonest experts, 0
utility-preserving anonymization, 2
culture, 974
Nordic, 757
sociolects, 4
colour, 32
color, 13400
cultural assumptions, 6
slurs, 8
obscene words, 5
geo-diverse, 2
annotation projection, 129
food, 151
violated, 78
disparity, 50
group DRO, 0
cross-cultural translation, 10
adaptation translation, 437
adaptive translation, 115
decolonise, 2
non-canonical, 80
contingent, 11
non-head words, 48
collocations, 371
binomial expressions, 1
syntactic confounds, 6
Tregex, 2
nested model comparison, 3
semantic idiosyncracy, 23
REB approval, 0
bar charts, 2940
line charts, 73
planning-based, 252
image captioning, 156
sentinel token, 0
bounding box positional embeddings, 0
white-box, 757
blunt questions, 0
blunt, 3
consistency tf-idf, 3
TrueSkill, 4
Kendall ranking correlation, 1
dialog exchanges, 41
in perspective, 1280
bot-bot, 250
Grice's maxim, 2
dyadic conversations, 17
low-effort, 230
adversarial filtering, 41
dissonance, 0
multi-source training, 198
many-to-many, 7470
saturation ensemble, 1
ensemble shared layers, 13
PWCCA, 0
event-level, 372
event-centric, 33
continued pre-training BART, 3
continually pre-trained BART, 0
human-labeling, 364
span recovering, 9
recovering, 383
three losses, 188
four losses, 48
GPU hours, 3020
multipart, 72
80/20/20, 0
classic models, 161
stack size, 6
pilot study, 153
VLU, 0
prompt-generation, 7
out-of-coverage, 89
support set, 460
optimize normalization, 14400
normalization optimization, 12
normalization parameter, 46
optimize bias, 43
bias optimization, 29
bias parameter, 62
cheaper, 42
BitFit, 3
heavy tail, 3
running example, 43
synthetic tasks, 420
side information, 351
tabular, 78
qualification quiz, 1
HIT, 679
hit, 679
1-4 scale, 25
1-5 scale, 25
Flesch, 23
linearization, 153
homogeneous, 96
Hitlin, 0
cold start, 76
confidentiality, 24
expertise, 195
inter-training, 167
cluster curriculum, 2
curriculum cluster, 2
stylistic distinction, 10
sequential information bottleneck, 4
sIB, 7
normalized mutual information, 7
NMI, 1
pseudo-label MLM, 0
pseudo-label BERT, 10
key-point analysis, 32
sparse patterns, 32
locality sensitive hashing, 80
LSH, 15
partitioning, 144
fuzzy clustering, 8
blocks, 485
finite experiments, 80
task taxonomy, 184
brain, 344
neuroscience, 142
brain activity, 503
analytic hierarchy process, 1
cognitive, 2460
exhaustive, 204
transductive TL, 0
inductive TL, 2
lifelong learning, 41
task embedding, 2710
Canberra distance, 1
non-target, 293
voxel, 6
hierarchical clustering, 96
long range, 440
over-sensitive, 94
oversensitive, 2
recency bias, 3
tempered sampling, 2
log-linear boosting, 0
undertraining, 3
single pass, 34
hyposensitivity, 0
soft matching, 23
online storage, 81
codebook-based, 4
decompression, 2
footprint, 63
overhead, 127
scalar quantization, 0
codebook compression, 2
softplus, 0
asymmetric distance computation, 0
precomputed, 23
product quantizer, 2
additive quantizer, 0
preloaded, 1
standalone, 104
entire set, 1790
SFT, 3
lottery ticket, 16
rewind, 1
model-independent, 831
model-agnostic, 383
Fisher information, 43
derogation, 2
lottery ticket selection, 0
lottery ticket winning, 16
compositionality, 458
compound divergence, 3
SPARQL, 30
compressed SPARQL, 0
arc, 459
dependency arc, 130
full-precision, 53
historical linguistics, 613
hand-annotated, 314
sporadically, 1
treebank, 2260
treebanking, 1980
desideratum, 30
desiderata, 24
standardised, 69
standardized, 302
IAST, 0
IPA, 30
tonogenesis, 0
toneme, 1
tonemes, 1
areal, 10
areal studies, 92
subtrate language, 4
vociferous, 0
Transkribus, 0
mutual information, 210
bilingual mutural information, 7
token-level, 547
sentence-level, 2120
up-weight, 146
mixed precision, 15
synchronously, 396
over-focus, 454
self-paced, 21
extra data, 192
yes/no, 177
not-answerable, 92
unanswerable, 72
decouple, 138
public policy, 87
HTML, 510
HTML elements, 29
snippet, 207
ETC, 1340
common error, 196
common errors, 210
L2R, 2
R2L, 3
relatively low probabilities, 15
threshold, 287
partially observable, 12
pertinently, 2
backward network, 23
backward decoder, 14
unconfident, 2
unconfidently, 1
bridging, 314
bridging resolver, 12
cross-task, 2330
learning-based, 5020
soft constraints, 92
element-wise multiplication similarity, 0
hardness coefficient, 0
dummy, 11
precision-oriented, 30
recall-oriented, 20
10-fold, 86
harsh, 87
max-margin, 43
Gaussian-distributed embeddings, 11
Gaussian embeddings, 72
prototypical networks, 69
variance estimation, 12
point embedding, 207
numerical stability, 2
5-shot, 145
1-shot, 851
ProtoBERT, 0
uniformity, 15
support data, 1360
micro-context, 76
BERTology, 9
Gricean, 6
unsaturated, 2
pioneering, 96
misprime, 1
multi-tower, 3
dual-encoder, 59
avoid saturation, 1
leakage, 27
query-context, 221
fine-to-coarse, 167
distributional semantics, 676
BERT-small, 178
token alignment, 160
embedding alignment, 340
cosine similarity temperature, 0
SSL, 21
fake tokens, 3
plug-and-play, 48
WordSim353, 9
disparate, 76
unseen, 920
minimal modification, 59
embedding space regularization, 10
embedding regularization, 102
open-vocabulary, 416
hallmark, 16
siamese, 138
multi-margin, 120
pairwise margin, 6
memory data, 736
lower bound, 46
upper bound, 92
quantized vector, 76
fuse, 135
syntax-aware, 6110
formulas, 240
triplet completion, 10
operator trees, 5
OPT, 51
multi-view, 1150
bi-directional knowledge transfer, 3
rehearsal, 3
replay, 36
service, 1460
abort, 6
abruptly, 9
experience replay, 9
progressive neural network, 8
compositional modules, 17
dissimilar, 60
anisotropy, 16
inner layers, 23
self-similarity, 95
swiss-roll, 0
swiss-roll manifold, 0
embedding geometry, 75
semantic geometry, 59
BOS token, 1
CWE, 2
CWEs, 3
readability, 638
control tokens, 33
discrete control tokens, 2
continuous control tokens, 1
word coverage, 397
GeForce, 0
disjointed, 1
constrain, 1180
constrains, 460
soft control, 9
stochastic search, 153
MaxPool, 2
kth, 135
k-th, 193
maxout, 5
MindSpore, 0
community use, 840
Standard Roman Orthography, 2
SRO, 1
child-directed, 57
community-based, 1140
EGIDS, 0
SRO-syllabics converter, 0
SRO-syllabics, 0
BoW format, 0
insert a space, 2
normative effects, 0
computer assisted language learning, 306
CALL, 1230
SoundHunters, 0
constituent order, 1450
WALS, 18
polynomial decay, 0
constituent shuffle, 0
word order, 1440
cross-lingual distantly-supervised, 3
type hierarchy, 339
ultra-fine, 10
FGET, 2
bilingual lexicon induction, 162
phrase retrieval, 188
momentum encoder, 4
Elasticsearch, 8
VecMap, 10
fine-grained discrete, 19
localization, 183
two-branch, 33
SHN, 1
NCE, 27
MMS, 3
InfoNCE, 2
codebook, 13
codeword, 4
softmin, 1
median rank, 0
trajectory, 97
sizable gap, 22
headroom, 3
as-is, 41300
prosody, 536
prosody variation, 57
style token, 72
frame-to-phoneme, 3
energy, 196
pitch and energy, 3
phoneme transformer, 69
mixture encodings, 200
text infilling evaluation, 60
attribute relevance, 57
NISF, 0
normalized inverse sentence frequency, 1
verbalizer, 6
evaluator set, 4250
Pearson Spearman Kendall, 0
model drift, 42
good-enough, 73
good enough, 73
langid, 4
Bhattacharyya, 387
Bhattacharyya coefficient, 2
socioeconomic factors, 4
lossy, 4
RBO, 0
ranked biased overlap, 2
generative-based, 392
deconfounding, 5
unfastened, 0
centering model, 21
generate negative examples, 30
AMR, 249
AMR graph, 191
logical flaws, 1
logical flaw, 1
cone, 25
whitening, 2
sampling bias, 92
word class, 992
EEG, 40
confounding dimensions, 1
weblogs, 46
RSVP, 6
Rapid Serial Visual Representation, 1
PsychoPy, 0
Flax/Jax, 0
False Discovery Rate, 1
FDR, 1
butterfly plot, 0
butterfly plots, 0
re-averaging, 143
Wilcoxon signed rank-test, 1
train-test overlap, 13
hash collision, 0
bloom filter, 2
suffix array, 14
MinHash, 0
edit similarity, 76
ILP, 57
integer linear programming, 64
inductive logic programming, 12
reasoner, 41
reasoner module, 17
biGRU, 21
existential predicate, 0
t-norm, 319
gradient flow, 12
invented predicate, 0
heuristic noise, 47
surface form, 264
fairseq noise, 5
fairseq noise function, 0
continue finetuning, 62
multi-task finetuning, 280
span-span, 980
subtree-subtree, 104
left-out, 51
expressivity, 40
large margin objective, 21
third-order, 204
MST decoding, 2
thorny, 5
delexicalize, 2
MoS, 69
unwieldy, 3
newswire, 155
unassimilated, 1
anglicism, 2
anglicisms, 2
Doccano, 2
sense2vec, 0
blenderbot finetune, 0
KGAT, 1
kernel graph attention network, 2
proverbial, 1
future predicting, 72
n-stream, 43
stream, 638
Free Bits, 4
full manual, 69
entirely manual, 41
gold-quality, 297
synset, 107
archaic usage, 0
archaic usages, 0
monosemous, 9
polysemous verb, 46
highly polysemous, 65
search errors, 2990
model errors, 1690
search errors model errors, 1740
cascade structure, 12
summary paraphrase, 5
MARL, 5
centralized training, 7
decentralized execution, 0
coverage mechanism, 104
channel, 460
joint actions, 95
AutoPhrase, 0
denovo, 1
denovo training, 0
de novo training, 0
training from scratch, 121
board-certified, 1
topic fusion, 18
expert-derived, 36
inference pass, 28
unwritten languages, 12
unwritten, 23
speech units, 2250
S2ST, 6
connectionist temporal classification, 20
CTC, 80
over-generation, 785
vocoder, 3
cepstral, 20
cepstrum, 4
telephone, 253
filterbank, 3
mean opinion scores, 8
MOS, 69
timeit, 55
PyPAPI, 0
memory-profiler, 0
incomplete labelling, 20
positive and unlabelled, 13
PU, 153
classification risk, 67
Rademacher, 0
Rademacher complexity, 0
covariate shift, 5
seasonal, 6
time-varying covariates, 0
demographics, 199
family-wise, 363
pre-collected, 217
unanswerable, 32
feature cluster, 284
100 classes, 50
confirmation bias, 3
loss correction, 898
cluster-level, 78
sieve, 25
sieving, 38
stable hyperparameters, 83
unstable hyperparameters, 0
hierarchical loss, 43
quality estimation, 435
noisy learning, 559
trusted instances, 0
trusted instance, 0
contexual parameters, 54
multi-encoder regularization, 72
contrastive test sets, 24
contrastive translation, 92
contrastive evaluation, 144
contrastive ranking, 30
contrastive rank, 48
along this path, 26
imputed, 23
NDO, 87
non-domunant order, 217
German NDO, 4
native language, 1020
native language effect, 72
ABX discriminability, 0
metamers, 0
reduced sensitivity, 2
contrastive predicting coding, 2
fifth layer, 35
probit regression, 0
phone contrasts, 46
acoustic scenes, 7
non-speech, 726
biologically plausible, 1
attention vector entropy, 1
attention flow, 56
task-modulated, 96
task-neutral, 281
untuned, 1
overcomplete, 3
hard-to-predict, 87
from-scratch, 405
orientation, 182
domain orientation, 15
orientation vector, 5
ADA, 51
any domain adaptation, 65
pivot features, 20
subtrahend, 0
weighted BCE loss, 0
BCE loss, 0
query style, 69
style query, 31
runner-up, 10
annotators' behaviors, 104
annotator behavior, 97
edit-based, 529
edit-based annotation, 44
re-annotated, 1020
re-annotate, 653
language discriminator, 322
gradient reversal, 5
reversal, 51
Sent2Vec, 4
capsule networks, 48
confidence penalty, 5
confidence penalty loss, 1
activation boundary, 3
entity anonymization, 10
anonymization, 58
non-parametric, 204
crosswordese, 0
rebus, 0
MIPS, 4
Satisfiability Modulo Theories, 0
snippet, 556
snippet-level, 25
receptive field, 6
consistency loss, 33
dynamic weights, 26
top-K parameterize, 0
top-K parameter, 8
top-K dynamic weights, 1
locator, 7
hyperparameter binary search, 2
binary search, 690
2-step binary search, 21
3-step binary search, 4
performant, 69
trigger, 360
world event knowledge, 69
pair constraints, 184
pair constraint, 112
memory store, 39
demonstrations, 1840
dynamic decoding, 72
dynamic prefix, 5
data-efficient, 1290
irrelevance classifier, 17
membership, 166
evolving, 321
warm-up proportion, 0
free-text-formed, 209
reporting bias, 89
superficial cues, 16
causal-strength, 4
FGM, 2
swift models, 7
super models, 109
instance-wise, 20
negative free energy, 0
free energy, 7
negative free, 18
reassembling, 1
ghost modules, 1
ghost, 9
multi-exit, 7
EBM, 60
artificial token, 57
noise ratio, 41
curious, 81
class distribution similarity, 6
class distribution similarities, 8
local intrinsic dimensionality, 1
intrinsic dimensionality, 2
Elec, 48
over-training, 1980
cognitive demand, 25
distribution learning, 374
guided conversation, 24
silver, 85
control signals, 25
E2E, 138
word-of-mouth, 8
childcare, 0
niche-targeting, 1
nichetargeting, 0
iteratively refine, 72
structured sentiment analysis, 131
SSA, 54
POS embedding, 127
part-of-speech embedding, 293
lemma embedding, 35
rotary position embedding, 0
Circle loss, 81
cosine annealing warm restarts, 0
kNN retrieval, 9
compact network, 108
datastore, 12
Meta-k, 33
Meta-k network, 9
one-plus-one, 86
entropy-based pruning, 2
DBSCAN, 2
BIRCH, 146
pivot selection, 10
random pruning, 7
pruning rate, 6
top-performed, 372
top-performing, 99
stable convergence, 4
validation curvature, 0
time budget, 31
nuclear norm, 0
inverse relation, 46
add inverse relation, 2
HP, 83
HPs, 2
SRCC, 0
curvature, 3
sample subgraphs, 2
subgraph sampling, 2
decouple search space, 6
quasi-random search, 1
robuster, 1
sentence compression, 129
look-ahead, 28
look-ahead mechanism, 0
moving average, 11
dense annotations, 138
information tree, 847
temporal grounding, 72
one-shot, 394
semantic relevance, 132
Intersectin over Union, 2
IoU, 48
surgically remove, 0
ASTE, 21
biaffine attention, 12
multi-channel, 70
classifier chains, 24
BERTwwm, 8
BERT-wwm, 9
enhancement module, 21
multi-step information propagation, 7
MSIP, 0
MixPooling, 42
heterogeneous graph, 121
betweenness centrality, 1
concretization, 1
thulac, 0
ictclas, 1
hanlp, 0
elbow, 1
lattice, 262
full-shot, 55
TPU Google Colab, 0
mixed prompting, 9
right-to-left re-ranking, 4
Parallel Iterative Edit, 4
Learner English, 283
NUCLE, 8
fast tokenizers, 11
quorum, 6
majority quorum, 0
errorful, 5
distributional similarity, 480
distributional inclusion hypothesis, 4
balanced inclusion, 8
neo-Davidsonian, 11
neo-Davisonian, 11
sentence generator, 207
Gödel t-norm, 0
Gödel probability, 0
centering theory, 135
AWQ, 0
entity grid, 14
depthwise convolution, 2
depthwise, 4
depth-wise, 7
Tree-Transformer, 73
one-sample t-test, 40
two-sample t-test, 49
premarked, 0
premark, 0
novel unigrams, 10
novel bigrams, 8
proverb, 11
surface overlap, 18
overfit to annotator, 51
VADER, 4
VADER sentiment, 1
bind, 175
recombine, 5
recombined, 5
out-of-context, 525
tree edit distance, 16
running example, 62
I will, 13100
physiognomy, 0
buy-in, 92
boiler-plate, 25
semi-standardized, 103
conductance, 2
recourse, 10
Green AI, 46
ethics washing, 0
information contrast model, 197
MAAC, 0
macro average accuracy, 10
category proximity, 5
adverse events, 69
one-error, 547
propensity, 16
extreme classification, 38
mono-label, 6
information content, 1530
statistical specificity, 9
similarity axioms, 1
linear contrast model, 15
a taxonomy of errors, 30
impenetrable, 2
medical simplification, 43
paucity, 115
codify, 18
decontextualization, 2
word-to-word, 17100
further adaptation, 275
scraping-bys, 84
PanLex, 43
eflomal, 1
induced lexicon, 164
graph perturbations, 10
concatenated edges, 7
graph autoregressive, 11
autoregressive graph, 12
tree autoregressive, 5
autoregressive tree, 5
generate-and-refine, 21
historical use, 277
Tree-BertScore, 0
Maximum Input Unit, 71
IME, 131
Chinese IME, 10
online vocabulary adaptation, 23
glyph, 25
pinpointing, 54
mention-entity, 661
Xhinua, 7
classy, 1
in the same ballpark, 0
historical analyses, 485
Args.me, 39
reduction factor, 21
text blocks, 402
a maximum length of 128, 0
laypersons, 6
superficial competitiveness, 0
ERM, 57
MiniLMv2, 1
worst class influence, 0
worst-group performance, 2
ballpark, 2
Adversarial Removal, 22
IRM, 24
V-REx, 6
proof graph, 51
unseen subjects, 16
continued concatenation, 7
stitched, 7
inference time, 532
forward chaining, 0
operating points, 47
faithfulness errors, 8
control models, 613
trade-off curve, 1
XSum hallucinations, 3
selector, 51
loss truncation, 3
education domain, 83
sub-skills, 6
unconventional punctuation, 0
focal event, 2
Cronbach, 1
Cronbach's coefficient alpha, 0
entropy statistics, 10
artificial development set, 24
order sensitivity, 48
block n-gram repetitions, 0
paid-for, 217
trigger tokens, 11
lexical bias, 70
unrealistic information, 161
LMI, 4
presupposition, 68
college student, 2200
data whitening, 1
readability metrics, 41
semantic understanding, 1030
class-incremental, 19
new classes, 562
old classes, 28
replay dataset, 6
data-free distillation, 4
non-special tokens, 10
code-mixing addition, 17
scalar knob, 1
writing assistance, 26
inference-time trick, 0
inference trick, 8
re-insertion, 23
stop-grad, 1
stop gradient, 2
3-point scale, 48
LaBSE, 9
dataless classification, 4
SN, 75
batch softmax, 3
in-batch negatives, 8
acceptability, 161
Welch's t-test, 2
Welch, 41
cross attention, 622
NVIDIA Triton, 0
heterogeneous knowledge, 145
conflicting knowledge, 20
label description, 152
label descriptions, 167
in-house, 243
self-describing, 10
nutrition, 8
banking, 605
information gain, 434
DBPedia Spotlight, 1
gradient-boosting, 41
dev-test correlation, 18
summary of findings, 178
K-fold, 23
minimum description length, 46
bagging, 43
model informed, 368
leave-of-out, 33
unstable variance, 5
semi-supervised few-shot, 28
VaTeX, 6
fill-in-the-blank, 36
fill-in-the-blanks, 109
extra spaces, 43
early-fusion, 19
late-fusion, 43
two-stream, 76
spatial structure, 45
single-stream, 23
dual-stream, 6
scene tree, 9
scene grammar, 7
scene graph, 43
UUAS, 3
undirected unlabelled attachment score, 1
fluctuate inconsistently, 0
informativeness distribution, 3
Matthew's correlation, 48
stockpile, 0
stockpiles, 0
word inclusion, 80
non-residual, 11
non-residual attention, 4
causal self-attention, 5
mean offset, 4
XBRL, 1
subword fragmentation, 1
token shape, 16
token magnitude, 18
IOB2, 1
Bloom embeddings, 3
Bloom embedding, 3
last-pooling, 230
structural statistics, 843
burn-in, 27
Prolific, 102
benepar, 0
Gibbs sampler, 5
Gibbs sampling, 24
legit, 4
data selection, 1260
flooding, 30
one backward pass, 2
accordance, 58
accordant, 1
gradient accordance, 0
sub-epoch, 1
stiffness, 0
well-received, 79
normalizing flows, 21
latent representation transformation, 10
location-scale, 2250
BIOES, 0
curly Iverson brackets, 0
Iverson, 2
beta skeleton graph, 0
beta skeleton, 0
skeleton, 30
noisy serialization, 1
serialization, 25
dimension inference, 49
unit inference, 1900
index inference, 26
Enron, 13
sketch, 160
table pre-training, 78
stereotyping, 109
MSc, 76
double switch, 3
citizen science, 19
untranslatable, 4
minimal pair, 83
US culture, 165
U.S. culture, 165
idiomacy, 0
social frames, 56
Social Frames, 56
re-translation, 766
wait-k, 31
uncover, 178
top-of-the-line, 54
non-interactive, 153
informal conversation, 1570
monologic, 2
ascription, 3
reified, 8
continuer, 2
Estoup, 0
prima facie, 2
turbulence, 2
repair initiator, 0
empirical grounding, 79
Appen, 4
internalize, 14
hyperbolic space, 43
tangent space, 5
dependency tree probing, 25
Frechet mean, 0
Lorentz centroid, 0
Einstein midpoint, 0
floating-point error, 0
half precision training, 2
top-notch, 5
predicate-argument, 394
node merging, 6
graph-to-text, 2810
text-to-graph, 3550
smatch, 27
espeto, 0
wash away, 0
self-talk, 80
product-of-experts, 28
PoE, 7
engineering-efficient, 250
cache-based, 69
long-form generation, 90
Markov logic networks, 40
citation, 30300
z-statistics, 27
unlikelihood, 9
stress test, 32
atomic, 153
atomic assertions, 1
citances, 1
citance, 5
check-worthy, 15
entity-replacement, 62
scientific NLP, 5460
metathesaurus, 10
overpredict, 1
AIDA, 134
AIDA framework, 5
personalization, 102
word-to-sequence, 1050
Academic Vocabulary List, 11
OOTB, 0
API limits, 4
PPLM, 2
Thing Explainer, 0
eschew, 7
bottleneck, 306
bottlenecked, 6
generative conditioning, 41
autoencoding, 460
pattern-exploiting training, 12
apple-to-apple, 184
foreign-language country, 5
Austronesian, 6
local entities, 197
auxilary supervision, 46
PTLM, 5
PTLMs, 43
embedder, 9
cookie theft, 4
within-set, 7700
paired perplexity, 10
Celex Lexical Database, 5
LDC96L14, 0
log frequency bands, 1
TTR, 12
ecco, 3
non-key, 315
subword graph, 6
Indiana University, 157
secondary information, 80
focus-attention, 378
saliency-selection, 2
graph self-supervised training, 14
graph pre-training, 167
ego-networks, 3
ego network, 3
protein ego-networks, 0
tree pre-training, 42
document rotation, 65
Gigaword, 69
LDC2011T07, 0
reentrancy, 10
AMR tree, 54
irregular, 35
time-series, 137
guided cross-attention, 23
time vector, 230
value-at-risk, 11
GDELT, 0
Pyramid method, 27
worthy, 62
SimAlign, 1
subtree information, 52
Eisner, 138
Eisner algorithm, 72
parsing-as-deduction, 10
spurious ambiguity, 13
hook trick, 2
head-splitting trick, 1
bookkeeping, 0
cost-augmented inference, 2
batchify, 1
batchify pytorch, 0
belief propagation, 15
soft trees, 51
meta relations, 58
IRC, 28
graph-to-sequence, 213
message passing, 43
document structure, 2500
document structures, 3350
hierarchical biases, 69
roundtrip consistency, 4
iterative refinements, 27
sketch, 160
hierarchical set, 271
residual error, 8
depth dropout, 0
cluster centroids, 28
recursive k-means, 1
hierarchical indexing, 2
well-handle, 266
Statistics Canada, 35
StatCan, 0
phrase deletion, 22
lisp, 25
lisp interpreter, 1
spurious program rate, 0
ToTTo, 23
spatial prompts, 16
quadrant, 5
hot-spots, 5
VisualGenome, 115
affinity score, 5
affinity scores, 5
unimodal, 82
neocolonialism, 1
community-based, 1150
polysynthesis, 6
decolonize, 1
SIGEL, 115
playfulness, 1
game with a purpose, 29
GWAP, 13
colorful pictures, 21
children books, 40
non-linguistic, 3900
non-linguistic input, 394
MQM, 23
function words, 811
interpolate, 116
functional structure, 575
functional roles, 144
hypophora, 0
SOAP, 6
patient-nurse, 43
patient-nurse summaries, 4
discharge summaries, 22
discharge, 108
stylistic differences, 24
SNOMED, 115
logical semantics, 313
overgeneration, 25
planner, 45
UCT, 33
branching factor, 6
OLIVE, 72
complementizer, 7
FOL, 193
intra-associations, 242
directed hypergraph, 3
graph walk, 65
path annotation, 41
over-smoothing, 43
hyperlink, 38
click-logs, 17
topical entity, 23
similarity between corpus, 552
AI debate, 6
argument mining, 314
sentence-pair classification, 140
table-filling, 23
mixup, 43
HarvestText, 0
parameter generator network, 8
PGN, 4
beta distribution, 4
OEI, 1
ideation, 26
color-coded, 13
meta-features, 102
geographical cultures, 20
at hand, 1150
defeasible logic, 0
hotlist, 0
trivial, 332
difficulty scores, 568
item response theory, 43
IRT, 10
pragmatics, 411
minimally contrastive, 1
BRISQUE score, 0
average dependency tree depth, 0
human body parts, 234
highway layer, 5
explanatory variables, 6
modelling negation, 460
timestamps, 51
code clone, 7
clone, 57
creative language, 56800
metonymy, 57
figurative paraphrase, 2
compositional generalization, 80
template engine, 8
repurpose, 29
BLEURT self-training, 1
prototype-based, 287
neural tensor networks, 21
Ollie, 6
testing concept activation vector, 1
TCAV, 1
Founta, 3
boosted sampling, 13
concept activation vector, 2
CAV, 4
implicit abuse, 25
explicit abuse, 81
multiple teachers, 89
sequential transfer learning, 18
weakly-labeled, 96
weakly-labelled, 37
imitation, 161
query sets, 288
construction loss, 21
label correlation, 115
Offensive Language Identification Dataset, 230
OLID, 79
ad hominem, 4
taxonomy tree, 41
taxonomy tree position, 1
multi-faceted CRF, 1
visual tokens, 41
patch, 13
patch-level, 2
embedding codebook, 4
fast clustering, 102
questionnaire, 105
PHQ9, 4
clinical instrument, 6
Beck Depression Inventory, 0
micromodel, 1
extra neuron, 115
anhedonia, 1
complex-value embedding, 10
ComplEx, 2640
modus operandi, 3
Advanced Mapping, 127
Generalized Procrustes, 2
BLI, 32
mimick-like, 26
typo, 56
hard negative generation, 6
Graphormer, 0
HTC, 9
NT-Xent, 2
stance detection, 144
efficient market hypothesis, 2
perculiarities, 40
cognitive distortion, 4
TextBlob, 1
HateSonar, 0
multi-hot, 48
unconstrained, 71
contextual bandit, 6
option set, 102
Pyro, 0
natural prior, 32100
adaptation-networks, 191
circumflex, 0
technology burnout, 0
approximate nearest neighbor, 10
beam blocking, 0
Bing search, 298
lemon picked, 0
siloed, 2
Gestalt pattern matching, 0
orthographic depth, 1
synesthetes, 1
jamos, 6
jamo, 4
representational similarity analysis, 21
RSA, 11
logography, 16
ipapy, 0
CIELuv, 0
Bonferroni correction, 1
binding theory, 24
chart-based, 1800
non-local, 185
paraphrase detection, 153
Shapley, 57
effective attention, 330
frequency penalty, 3
presence penalty, 1
length embedding, 104
noun chunks, 25
semi-structured, 161
prototypical graph, 24
edge-oriented, 20
statistically stable, 4
Spreading-Activation Theory, 0
relatedness, 508
l2 similarity, 7
Gaussian distance, 4
fuzzy actions, 1
fuzzy operations, 6
fuzzy grammar, 6
two-layer, 443
fuzzy comparison, 27
multi-channel, 70
single character words, 67
contrast vanishing, 1
TextRank, 19
Mahalanobis, 6
Mahalanobis distance, 4
geometrical disparity, 0
imposter, 1
one-off, 420
translation noise, 348
morphological alternations, 23
non-concatenative morphology, 17
two-tier, 23
Bantu, 20
Bantu languages, 48
desktop machine, 282
compact region, 1
simply-connected region, 1
simply-connected, 6
Gaussian Hypothesis Testing, 0
open space risk, 4
counseling, 40
soft positional encoding, 9
Zenserp, 0
position collision, 0
Qualtrics, 0
integrated gradients, 48
Riemann approximation, 0
programming language, 529
path search, 436
secondary pre-training, 4
span denoising, 1
fewer gradient updates, 5
Hungarian algorithm, 14
shortlist, 7
noisy matching, 108
gumbel-sinkhorn, 0
systematic generalization, 60
positional embedding downscaling, 0
restart mechanism, 1
poset, 1
TLM, 9
ranking loss, 56
constrastive-data-selection, 41
cross-accelerator, 1
progressive stacking, 0
m-USE, 1670
additive margin, 3
vocoder, 3
vocoders, 3
proprietary, 37
meta-parameters, 46
phonemizer, 0
second order derivatives, 1
guided attention loss, 7
phonetically balanced, 20
inverted index mapping, 1
Louvain method, 2
Louvain, 138
scientific WSI, 20
SPIKE, 21
aggravate, 9
exponential moving average, 3
Moses, 176
inverse square root, 1
inverse square root learning rate, 0
non-autoregressive transformer, 69
glancing, 26
